{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5acfb05-bda4-4b6c-8905-bf09e0320990",
   "metadata": {},
   "source": [
    "### 1.洗床数据清洗与整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83ee7b16-6726-4061-9a5c-207b6902ee0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "year:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "month:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "month:   8%|▊         | 1/12 [00:04<00:45,  4.15s/it]\u001b[A\n",
      "month:  17%|█▋        | 2/12 [00:08<00:40,  4.01s/it]\u001b[A\n",
      "month:  25%|██▌       | 3/12 [00:13<00:42,  4.67s/it]\u001b[A\n",
      "month:  33%|███▎      | 4/12 [00:18<00:39,  4.91s/it]\u001b[A\n",
      "month:  42%|████▏     | 5/12 [00:24<00:35,  5.09s/it]\u001b[A\n",
      "month:  50%|█████     | 6/12 [00:29<00:30,  5.09s/it]\u001b[A\n",
      "month:  58%|█████▊    | 7/12 [00:34<00:25,  5.20s/it]\u001b[A\n",
      "month:  67%|██████▋   | 8/12 [00:40<00:20,  5.23s/it]\u001b[A\n",
      "month:  75%|███████▌  | 9/12 [00:44<00:15,  5.05s/it]\u001b[A\n",
      "month:  83%|████████▎ | 10/12 [00:49<00:10,  5.02s/it]\u001b[A\n",
      "month:  92%|█████████▏| 11/12 [00:54<00:04,  4.90s/it]\u001b[A\n",
      "month: 100%|██████████| 12/12 [00:59<00:00,  4.96s/it]\u001b[A\n",
      "year:  25%|██▌       | 1/4 [00:59<02:58, 59.51s/it]\n",
      "month:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "month:   8%|▊         | 1/12 [00:05<01:02,  5.72s/it]\u001b[A\n",
      "month:  17%|█▋        | 2/12 [00:10<00:52,  5.26s/it]\u001b[A\n",
      "month:  25%|██▌       | 3/12 [00:16<00:49,  5.49s/it]\u001b[A\n",
      "month:  33%|███▎      | 4/12 [00:21<00:42,  5.28s/it]\u001b[A\n",
      "month:  42%|████▏     | 5/12 [00:26<00:36,  5.21s/it]\u001b[A\n",
      "month:  50%|█████     | 6/12 [00:31<00:31,  5.28s/it]\u001b[A\n",
      "month:  58%|█████▊    | 7/12 [00:37<00:26,  5.36s/it]\u001b[A\n",
      "month:  67%|██████▋   | 8/12 [00:42<00:21,  5.39s/it]\u001b[A\n",
      "month:  75%|███████▌  | 9/12 [00:47<00:15,  5.21s/it]\u001b[A\n",
      "month:  83%|████████▎ | 10/12 [00:53<00:10,  5.38s/it]\u001b[A\n",
      "month:  92%|█████████▏| 11/12 [00:58<00:05,  5.44s/it]\u001b[A\n",
      "month: 100%|██████████| 12/12 [01:04<00:00,  5.41s/it]\u001b[A\n",
      "year:  50%|█████     | 2/4 [02:04<02:05, 62.67s/it]\n",
      "month:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "month:   8%|▊         | 1/12 [00:05<00:59,  5.45s/it]\u001b[A\n",
      "month:  17%|█▋        | 2/12 [00:10<00:54,  5.41s/it]\u001b[A\n",
      "month:  25%|██▌       | 3/12 [00:16<00:50,  5.67s/it]\u001b[A\n",
      "month:  33%|███▎      | 4/12 [00:22<00:44,  5.51s/it]\u001b[A\n",
      "month:  42%|████▏     | 5/12 [00:27<00:38,  5.53s/it]\u001b[A\n",
      "month:  50%|█████     | 6/12 [00:33<00:33,  5.60s/it]\u001b[A\n",
      "month:  58%|█████▊    | 7/12 [00:38<00:27,  5.57s/it]\u001b[A\n",
      "month:  67%|██████▋   | 8/12 [00:44<00:21,  5.48s/it]\u001b[A\n",
      "month:  75%|███████▌  | 9/12 [00:49<00:16,  5.57s/it]\u001b[A\n",
      "month:  83%|████████▎ | 10/12 [00:55<00:11,  5.53s/it]\u001b[A\n",
      "month:  92%|█████████▏| 11/12 [01:00<00:05,  5.53s/it]\u001b[A\n",
      "month: 100%|██████████| 12/12 [01:06<00:00,  5.52s/it]\u001b[A\n",
      "year:  75%|███████▌  | 3/4 [03:10<01:04, 64.32s/it]\n",
      "month:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "month:   8%|▊         | 1/12 [00:06<01:06,  6.06s/it]\u001b[A\n",
      "month:  17%|█▋        | 2/12 [00:11<00:55,  5.54s/it]\u001b[A\n",
      "month:  25%|██▌       | 3/12 [00:18<00:56,  6.27s/it]\u001b[A\n",
      "month:  33%|███▎      | 4/12 [00:24<00:48,  6.08s/it]\u001b[A\n",
      "month:  42%|████▏     | 5/12 [00:29<00:40,  5.85s/it]\u001b[A\n",
      "month:  50%|█████     | 6/12 [00:34<00:34,  5.68s/it]\u001b[A\n",
      "month:  58%|█████▊    | 7/12 [00:40<00:28,  5.73s/it]\u001b[A\n",
      "month:  67%|██████▋   | 8/12 [00:46<00:22,  5.64s/it]\u001b[A\n",
      "month:  75%|███████▌  | 9/12 [00:51<00:16,  5.46s/it]\u001b[A\n",
      "month:  83%|████████▎ | 10/12 [00:56<00:10,  5.50s/it]\u001b[A\n",
      "month: 100%|██████████| 12/12 [01:02<00:00,  5.18s/it]\u001b[A\n",
      "year: 100%|██████████| 4/4 [04:12<00:00, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '干熄焦生产记录台账/2022/干熄焦生产记录台账（12月）.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import calendar\n",
    "import os\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 初始化文件\n",
    "if os.path.exists('RegenerationRawInfo.csv'):\n",
    "    os.remove('RegenerationRawInfo.csv')\n",
    "\n",
    "valid_columns = [2,5,8]\n",
    "years = [2019,2020,2021,2022]\n",
    "\n",
    "regeneration_df = pd.DataFrame({'date':[], 'regeneration':[]})\n",
    "regeneration_df.to_csv(\"RegenerationRawInfo.csv\",mode='a',index=False)\n",
    "\n",
    "\n",
    "for year in tqdm(years,desc=\"year\"):\n",
    "\n",
    "\n",
    "    # 遍历路径文件\n",
    "    for month in tqdm(range(1,13,1),desc=\"month\"):\n",
    "        file_name = '干熄焦生产记录台账/{0}/干熄焦生产记录台账（{1}月）.xlsx'.format(year,month)\n",
    "        #file_date_info = re.findall(r'\\d{1,}', file_name) # 提取路径文件信息(年、月）\n",
    "        #month = file_date_info[1]\n",
    "        # year = file_date_info[0]\n",
    "\n",
    "        # 返回（当月总周数，当月总天数）\n",
    "        month_range = calendar.monthrange(int(year),int(month))\n",
    "        \n",
    "        # 遍历表单\n",
    "        for day in range(1,month_range[1]+1,1):  # 从第1天开始至当月最后一天\n",
    "            try:\n",
    "                regeneration_date = pd.read_excel(file_name, sheet_name = \"{}日\".format(day), header=None) # 读取当日表单\n",
    "            except FileNotFoundError as file_error:\n",
    "                print(file_error)\n",
    "                break\n",
    "                \n",
    "            if (year < 2020 or ( year==2020 and month <= 9)):\n",
    "                valid_index1 = 25\n",
    "                valid_index2 = 26\n",
    "            else :\n",
    "                valid_index1 = 27\n",
    "                valid_index2 = 28\n",
    "                \n",
    "            regeneration_cell = regeneration_date.iloc[valid_index1:valid_index2,[2,5,8]].astype(str) # 只保留包含洗床单元格的数据\n",
    "            \n",
    "            # 构建日期DataFrame\n",
    "            regenerate_date = {'date':[\"{0}-{1}-{2}\".format(year, month, day)]} # 再生日期信息\n",
    "            regeneration_date_df = pd.DataFrame(data=regenerate_date)\n",
    "        \n",
    "            # 对单元格遍历，拆分、分割\n",
    "            for valid_column in valid_columns:\n",
    "                regeneration_split_cell = regeneration_cell[valid_column].T.str.split(r'\\s+', expand=True) # 转置,（以至少1个空格)分割\n",
    "            \n",
    "                # 根据拆分的单元格长度，遍历追加入文件\n",
    "                for l in range(int(regeneration_split_cell.size)):\n",
    "                    regeneration_split_cell[l] =  regeneration_split_cell[l].astype(str)\n",
    "                        \n",
    "                    # 重建洗床信息DataFrame\n",
    "                    regeneration_split_cell_value = regeneration_split_cell[l].values\n",
    "                    regeneration_split_cell_value_df = pd.DataFrame(regeneration_split_cell_value)\n",
    "                    frames = [regeneration_date_df, regeneration_split_cell_value_df]\n",
    "                    result = pd.concat(frames,join=\"outer\",axis=1, ignore_index=True)\n",
    "                    result.to_csv(\"RegenerationRawInfo.csv\",mode='a',header=False, index=False)\n",
    "\n",
    "# 剔除空行\n",
    "regeneration_raw_info = pd.read_csv(\"RegenerationRawInfo.csv\")\n",
    "regeneration_raw_info.dropna(axis='rows', inplace=True)\n",
    "regeneration_raw_info.reset_index(drop=True, inplace=True)  # drop=True能避免把旧列插入重排列\n",
    "\n",
    "regeneration_raw_info.to_csv(\"RegenerationRawInfo.csv\",mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f9d70-2a6d-426d-a6d6-7f5c65cbc449",
   "metadata": {},
   "source": [
    "### 2.洗床数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "47824c17-0aa1-44bd-807f-a8e76bffa632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rg_info = pd.read_csv(\"RegenerationRawInfo.csv\")\n",
    "pd.to_datetime(rg_info.date)\n",
    "\n",
    "rg_split = rg_info['regeneration'].str.split(r' ?分? ?再生|，|进|置换', regex=True, expand=True)\n",
    "\n",
    "rg_split['time'] = rg_split[0]\n",
    "rg_split['cation_resin'] = rg_split[1]\n",
    "\n",
    "rg_split_draft = pd.concat([rg_info.date, rg_split['time'], rg_split['cation_resin']], axis=1)\n",
    "rg_split_draft.replace(\"：\",\":\", inplace=True)\n",
    "rg_split_draft.to_csv(\"RegenerationSplitInfo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6a35774-38ef-4350-92ab-f5b2a47fda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_draft = pd.read_csv(\"RegenerationSplitInfo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418cc5ba-bd03-461a-bcf2-7a12b511ac88",
   "metadata": {},
   "source": [
    "1#阳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a888007-d64d-4f33-9b2a-dbf9518d35c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cation_resin_1 = rg_draft.loc[rg_draft.iloc[:,2].str.contains(r'1#阳床',regex=True, na=False)]\n",
    "\n",
    "# 规范数据格式\n",
    "cation_resin_1 = cation_resin_1[cation_resin_1['cation_resin'].notnull()].copy()\n",
    "cation_resin_1.replace(r'：',\":\", regex=True, inplace=True)\n",
    "cation_resin_1.replace(r';',\":\", regex=True, inplace=True)\n",
    "cation_resin_1.replace(r'点',\":\", regex=True, inplace=True)\n",
    "\n",
    "# 统一时间格式\n",
    "cation_resin_1['time'] = pd.to_datetime(cation_resin_1['date'] +\" \"+ cation_resin_1['time'])\n",
    "\n",
    "# 洗床间隔时间\n",
    "cation_resin_1['time_diff'] = pd.to_datetime(cation_resin_1['time']).diff()\n",
    "\n",
    "cation_resin_1.to_csv(\"cation_resin_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca498a-0e2e-48f2-be3b-8d844151573e",
   "metadata": {},
   "source": [
    "2#阳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60c9601b-4339-4a9b-b7c2-c2651ccddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cation_resin_2 = rg_draft.loc[rg_draft.iloc[:,2].str.contains(r'2#阳',regex=True, na=False)]\n",
    "\n",
    "# 规范数据格式\n",
    "cation_resin_2 = cation_resin_2[cation_resin_2['cation_resin'].notnull()].copy()\n",
    "cation_resin_2.replace(r'：',\":\", regex=True, inplace=True)\n",
    "cation_resin_2.replace(r';',\":\", regex=True, inplace=True)\n",
    "cation_resin_2.replace(r'点',\":\", regex=True, inplace=True)\n",
    "cation_resin_2.replace(r'\\.',\":\", regex=True, inplace=True)\n",
    "cation_resin_2.replace(r'::',\":\", regex=True, inplace=True)\n",
    "\n",
    "# 时间标准化\n",
    "cation_resin_2['time'] = pd.to_datetime(cation_resin_2['date'] +\" \"+ cation_resin_2['time'])\n",
    "\n",
    "# 洗床间隔时间\n",
    "cation_resin_2['time_diff'] = pd.to_datetime(cation_resin_2['time']).diff()\n",
    "\n",
    "cation_resin_2.to_csv(\"cation_resin_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c363b0-eb9a-4135-b927-845dec2b292b",
   "metadata": {},
   "source": [
    "3#阳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e121c2f4-d8a7-462e-b59a-3614ccc0511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cation_resin_3 = rg_draft.loc[rg_draft.iloc[:,2].str.contains(r'3#阳',regex=True, na=False)]\n",
    "\n",
    "# 规范数据格式\n",
    "cation_resin_3 = cation_resin_3[cation_resin_3['cation_resin'].notnull()].copy()\n",
    "cation_resin_3.replace(r'：',\":\", regex=True, inplace=True)\n",
    "cation_resin_3.replace(r';',\":\", regex=True, inplace=True)\n",
    "cation_resin_3.replace(r'点',\":\", regex=True, inplace=True)\n",
    "cation_resin_3.replace(r'\\.',\":\", regex=True, inplace=True)\n",
    "cation_resin_3.replace(r'::',\":\", regex=True, inplace=True)\n",
    "\n",
    "# 时间标准化\n",
    "cation_resin_3['time'] = pd.to_datetime(cation_resin_3['date'] +\" \"+ cation_resin_3['time'])\n",
    "\n",
    "# 洗床间隔时间\n",
    "cation_resin_3['time_diff'] = pd.to_datetime(cation_resin_3['time']).diff()\n",
    "\n",
    "cation_resin_3.to_csv(\"cation_resin_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f8902-2d09-4285-874f-3540dd7d81e6",
   "metadata": {},
   "source": [
    "### 3.异常数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c3142-9a89-4de3-82c4-9155e576d241",
   "metadata": {},
   "source": [
    "2021-01-14 中间间隔143天40小时系1#阳床树脂泄漏维护，故剔除该行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bc8d329c-c0db-4362-ae03-3d5fb9f1282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cation_resin_1.drop([cation_resin_1['time_diff'].idxmax()], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e6c0a-4da8-49ee-877d-3835a5a0c8a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1#阳床异常数据处理：\n",
    "1.删除使用时长大于60h，小于4h的数据。（床体维护）\n",
    "\n",
    "2.大于50h的数据乘以0.9备用系数。（床体备用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8bbc5aae-4155-4005-9e0c-cceecda1b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 阳床间隔单位为小时\n",
    "cation_resin_1['time_diff'] = (cation_resin_1['time_diff'].dt.total_seconds() / 60 / 60 ).round(2)\n",
    "cation_resin_2['time_diff'] = (cation_resin_2['time_diff'].dt.total_seconds() / 60 / 60 ).round(2)\n",
    "cation_resin_3['time_diff'] = (cation_resin_3['time_diff'].dt.total_seconds() / 60 / 60 ).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c5915245-f4ff-49fe-9d39-88a1ba8ac852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authentic_cs_1 = cation_resin_1.loc[(cation_resin_1['time_diff'] < 60) & (cation_resin_1['time_diff'] > 6)]\n",
    "authentic_cs_1_td = authentic_cs_1['time_diff'].copy()\n",
    "(authentic_cs_1_td.loc[(authentic_cs_1['time_diff'] > 50 )]) *= 0.9\n",
    "authentic_cs_1_td.to_csv(\"authentic_cs_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "75b61eae-d2d3-44e3-880a-4380371a1b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    772.000000\n",
       "mean      31.271142\n",
       "std       11.804803\n",
       "min        6.500000\n",
       "25%       21.500000\n",
       "50%       31.600000\n",
       "75%       40.980000\n",
       "max       53.892000\n",
       "Name: time_diff, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentic_cs_1_td.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b977e18-3c6d-4cbf-87d3-f22e88a89cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authentic_cs_2 = cation_resin_2.loc[(cation_resin_2['time_diff'] < 60) & (cation_resin_2['time_diff'] > 6)]\n",
    "authentic_cs_2_td = authentic_cs_2['time_diff'].copy()\n",
    "(authentic_cs_2_td.loc[(authentic_cs_2['time_diff'] > 50 )]) *= 0.9\n",
    "authentic_cs_2_td.to_csv(\"authentic_cs_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8117139a-da12-499a-98c6-e6501117575c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    809.000000\n",
       "mean      31.815304\n",
       "std       10.725194\n",
       "min        7.000000\n",
       "25%       23.500000\n",
       "50%       31.970000\n",
       "75%       39.800000\n",
       "max       53.640000\n",
       "Name: time_diff, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentic_cs_2_td.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bdd21dd8-332d-498b-9222-599065b7f622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authentic_cs_3 = cation_resin_3.loc[(cation_resin_3['time_diff'] < 60) & (cation_resin_3['time_diff'] > 6)]\n",
    "authentic_cs_3_td = authentic_cs_3['time_diff'].copy()\n",
    "(authentic_cs_3_td.loc[(authentic_cs_3['time_diff'] > 50 )]) *= 0.9\n",
    "authentic_cs_3_td.to_csv(\"authentic_cs_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "294ce7d6-cc38-4683-a9e8-4c51570625fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    588.000000\n",
       "mean      34.404155\n",
       "std       11.569159\n",
       "min        6.080000\n",
       "25%       25.327500\n",
       "50%       34.050000\n",
       "75%       45.450000\n",
       "max       53.847000\n",
       "Name: time_diff, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentic_cs_3_td.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
